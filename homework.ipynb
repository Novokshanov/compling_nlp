{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите 1 любой способ сломать токенизацию на предложения функцией sentenize из библиотеки razdel. Придумайте (или найдите на каком-то корпусе) такое предложение (или несколько предложений), которое будет некорректно разобрано sentenize, но при этом будет грамматически корректным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['«Слава богу, насилу вы приехали, – сказала девушка.',\n",
       " '– Чуть было вы барышню не уморили.»']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код\n",
    "\n",
    "text0 = '«Слава богу, насилу вы приехали, – сказала девушка. – Чуть было вы барышню не уморили.»'\n",
    "\n",
    "sents = list(sentenize(text0))\n",
    "[sent.text for sent in sents]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Токенизация Mystem vs razdel.tokenize (2 балла)\n",
    "\n",
    "\n",
    "Токенизируйте текст с помощью razdel и с помощью Mystem. Найдите различия в токенизациях. Что по вашему работает лучше на приведенном тексте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*На приведенном тексте лучше работает razdel, так как он игнориирует переносы строк, а также не записывает пробелы как отдельные токены. '1,4' razdel также более удачно собрал в один токен, а не разбил на три, как mystem. Mystem, в свою очередь, более удачно собрал см3 в один токен. Сравнивал я, естественно, разные промежутки.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Вторым и третьим открытыми белыми карликами стали Сириус B и Процион B. В 1844 году директор Кёнигсбергской обсерватории Фридрих Бессель, анализируя данные наблюдений, которые велись с 1755 года, обнаружил, что Сириус, ярчайшая звезда земного неба, и Процион периодически, хотя и весьма слабо, отклоняются от прямолинейной траектории движения по небесной сфере[5]. Бессель пришёл к выводу, что у каждой из них должен быть близкий спутник. Сообщение было встречено скептически, поскольку слабый спутник оставался ненаблюдаемым, а его масса должна была быть достаточно велика — сравнимой с массой Сириуса и Проциона, соответственно.\n",
    "\n",
    "В январе 1862 года Элвин Грэхэм Кларк, юстируя 18-дюймовый рефрактор, самый большой на то время телескоп в мире (Dearborn Telescope), впоследствии поставленный семейной фирмой Кларков в обсерваторию Чикагского университета, обнаружил в непосредственной близости от Сириуса тусклую звёздочку. Это был спутник Сириуса, Сириус B, предсказанный Бесселем[6]. А в 1896 году американский астроном Д. М. Шеберле открыл Процион B, подтвердив тем самым и второе предсказание Бесселя.\n",
    "\n",
    "В 1915 году американский астроном Уолтер Сидней Адамс измерил спектр Сириуса B. Из измерений следовало, что его температура не ниже, чем у Сириуса A (по современным данным, температура поверхности Сириуса B составляет 25 000 K, а Сириуса A — 10 000 К), что, с учётом его в 10 000 раз меньшей, чем у Сириуса A, светимости указывает на очень малый радиус и, соответственно, высокую плотность — 106 г/см3 (плотность Сириуса ~0,25 г/см3, плотность Солнца ~1,4 г/см3).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize as razdel_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['плотность',\n",
       " '—',\n",
       " '106',\n",
       " 'г',\n",
       " '/',\n",
       " 'см',\n",
       " '3',\n",
       " '(',\n",
       " 'плотность',\n",
       " 'Сириуса',\n",
       " '~',\n",
       " '0,25',\n",
       " 'г',\n",
       " '/',\n",
       " 'см',\n",
       " '3',\n",
       " ',',\n",
       " 'плотность',\n",
       " 'Солнца',\n",
       " '~',\n",
       " '1,4',\n",
       " 'г',\n",
       " '/',\n",
       " 'см',\n",
       " '3',\n",
       " ')',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваш код\n",
    "#sents = list(sentenize(text))\n",
    "#sents_razdel = [sent.text for sent in sents]\n",
    "[token.text for token in list(razdel_tokenize(text))[265:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'плотность',\n",
       " ' — ',\n",
       " '106',\n",
       " ' ',\n",
       " 'г',\n",
       " '/',\n",
       " 'см3',\n",
       " ' (',\n",
       " 'плотность',\n",
       " ' ',\n",
       " 'Сириуса',\n",
       " ' ~',\n",
       " '0',\n",
       " ',',\n",
       " '25',\n",
       " ' ',\n",
       " 'г',\n",
       " '/',\n",
       " 'см3',\n",
       " ', ',\n",
       " 'плотность',\n",
       " ' ',\n",
       " 'Солнца',\n",
       " ' ~',\n",
       " '1',\n",
       " ',',\n",
       " '4',\n",
       " ' ',\n",
       " 'г',\n",
       " '/',\n",
       " 'см3',\n",
       " ')',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Достаём словоформы из анализа\n",
    "words_analized = mystem.analyze(text)\n",
    "[parse['text'] for parse in words_analized if parse.get('text')][440:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Лемматизация Mystem vs Pymorphy (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируйте текст с помощью mystem и pymorphy. Найдите различия в лемматизации. Что по вашему работает лучше на приведенном тексте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно: для пайморфи используйте токенизацию из mystem, чтобы исключить влияние токенизации на результат. Анализируйте только значимые различия, а не технические особенности (не сравнивайте скорость работы и удобность интерфейса)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mystem работает лучше. Например, он правильно разобрал слово 'данные', в отличие от pymorphy, а также даёт более правильные начальные формы глаголов ('стали' - 'стать', а не 'становиться').*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код\n",
    "tokenized_text = [parse['text'] for parse in words_analized if parse.get('text')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_analized = [morph.parse(token) for token in tokenized_text]\n",
    "words_analized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for word in words_analized:\n",
    "    lemmas.append(word[0].normal_form)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', ',\n",
       " 'анализировать',\n",
       " ' ',\n",
       " 'дать',\n",
       " ' ',\n",
       " 'наблюдение',\n",
       " ', ',\n",
       " 'который',\n",
       " ' ',\n",
       " 'вестись',\n",
       " ' ',\n",
       " 'с',\n",
       " ' ',\n",
       " '1755',\n",
       " ' ',\n",
       " 'год',\n",
       " ', ',\n",
       " 'обнаружить',\n",
       " ', ',\n",
       " 'что',\n",
       " ' ',\n",
       " 'сириус',\n",
       " ', ',\n",
       " 'яркий',\n",
       " ' ',\n",
       " 'звезда',\n",
       " ' ',\n",
       " 'земной',\n",
       " ' ',\n",
       " 'небо',\n",
       " ', ',\n",
       " 'и',\n",
       " ' ',\n",
       " 'процион',\n",
       " ' ',\n",
       " 'периодически',\n",
       " ', ',\n",
       " 'хотя',\n",
       " ' ',\n",
       " 'и']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Лемматизация pymorphy\n",
    "lemmas[40:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', ',\n",
       " 'анализировать',\n",
       " ' ',\n",
       " 'данные',\n",
       " ' ',\n",
       " 'наблюдение',\n",
       " ', ',\n",
       " 'который',\n",
       " ' ',\n",
       " 'вестись',\n",
       " ' ',\n",
       " 'с',\n",
       " ' ',\n",
       " '1755',\n",
       " ' ',\n",
       " 'год',\n",
       " ', ',\n",
       " 'обнаруживать',\n",
       " ', ',\n",
       " 'что',\n",
       " ' ',\n",
       " 'сириус',\n",
       " ', ',\n",
       " 'яркий',\n",
       " ' ',\n",
       " 'звезда',\n",
       " ' ',\n",
       " 'земной',\n",
       " ' ',\n",
       " 'небо',\n",
       " ', ',\n",
       " 'и',\n",
       " ' ',\n",
       " 'процион',\n",
       " ' ',\n",
       " 'периодически',\n",
       " ', ',\n",
       " 'хотя',\n",
       " ' ',\n",
       " 'и']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Лемматизация mystem\n",
    "mystem.lemmatize(text)[40:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Лемматизация в SpaCy (2 балла)\n",
    "\n",
    "С помощью Spacy (модель для русского языка) лемматизируйте тот же текст. Проверьте есть ли различия с Mystem и Pymoprhy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Качество лемматизации данного текста идентично Mystem и в уже описанных выше параметрах лучше, чем у Pymorphy. По сравнению с Mystem, Spacy удобнее тем, что сразу удаляет из выдачи пробелы.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "spacy_lemms = []\n",
    "\n",
    "for sent in doc.sents: # достаем предложения\n",
    "    for token in sent: # достаем токены\n",
    "        spacy_lemms.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'второй',\n",
       " 'и',\n",
       " 'третий',\n",
       " 'открытый',\n",
       " 'белый',\n",
       " 'карлик',\n",
       " 'стать',\n",
       " 'сириус',\n",
       " 'b',\n",
       " 'и',\n",
       " 'процион',\n",
       " 'b.',\n",
       " 'в',\n",
       " '1844',\n",
       " 'год',\n",
       " 'директор',\n",
       " 'кёнигсбергский',\n",
       " 'обсерватория',\n",
       " 'фридрих',\n",
       " 'бессель',\n",
       " ',',\n",
       " 'анализировать',\n",
       " 'данные',\n",
       " 'наблюдение',\n",
       " ',',\n",
       " 'которые',\n",
       " 'вестись',\n",
       " 'с',\n",
       " '1755',\n",
       " 'год',\n",
       " ',',\n",
       " 'обнаружить',\n",
       " ',',\n",
       " 'что',\n",
       " 'сириус',\n",
       " ',',\n",
       " 'яркий',\n",
       " 'звезда',\n",
       " 'земной']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_lemms[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5*. Дизамбигуация в Mystem (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*необязательное задание на 10 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из фичей майстема - контекстная дизамбигуация (т.е. определение правильного разбора в зависимости от контекста)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите mystem на очищенном тексте с дизамбигуацией и без и проверьте есть ли какие-то различия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Различие заключается в количестве лексических и грамматических разборов (в чем, кажется и есть смысл дизамбигуации). Интересно, что дазамбигуированный разбор в проверенных случаях оказался правильным.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код\n",
    "mystem_disambiguation = Mystem(disambiguation=True)\n",
    "analized_text_disambiguated = mystem_disambiguation.analyze(text)\n",
    "\n",
    "mystem = Mystem(disambiguation=False)\n",
    "analized_text = mystem.analyze(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n'},\n",
       " {'analysis': [{'lex': 'второй',\n",
       "    'wt': 0.986135184,\n",
       "    'gr': 'ANUM=(дат,мн|твор,ед,муж|твор,ед,сред)'}],\n",
       "  'text': 'Вторым'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'третий',\n",
       "    'wt': 0.9944396734,\n",
       "    'gr': 'ANUM=(дат,мн|твор,ед,муж|твор,ед,сред)'}],\n",
       "  'text': 'третьим'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'открытый', 'wt': 0.959315763, 'gr': 'A=твор,мн,полн'}],\n",
       "  'text': 'открытыми'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'белый', 'wt': 0.9932845421, 'gr': 'A=твор,мн,полн'}],\n",
       "  'text': 'белыми'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'карлик', 'wt': 1, 'gr': 'S,муж,од=твор,мн'}],\n",
       "  'text': 'карликами'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'становиться',\n",
       "    'wt': 0.9821285244,\n",
       "    'gr': 'V,нп=прош,мн,изъяв,сов'}],\n",
       "  'text': 'стали'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'сириус',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'Сириус'},\n",
       " {'text': ' '},\n",
       " {'analysis': [], 'text': 'B'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'}]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analized_text_disambiguated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n'},\n",
       " {'analysis': [{'lex': 'второй',\n",
       "    'wt': 0.986135184,\n",
       "    'gr': 'ANUM=(дат,мн|твор,ед,муж|твор,ед,сред)'},\n",
       "   {'lex': 'второе',\n",
       "    'wt': 0.01386481599,\n",
       "    'gr': 'S,сред,неод=(дат,мн|твор,ед)'}],\n",
       "  'text': 'Вторым'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='},\n",
       "   {'lex': 'и', 'wt': 1.020511514e-05, 'gr': 'INTJ='},\n",
       "   {'lex': 'и',\n",
       "    'wt': 6.379604644e-06,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'},\n",
       "   {'lex': 'и', 'wt': 6.37957056e-06, 'gr': 'PART='}],\n",
       "  'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'третий',\n",
       "    'wt': 0.9944396734,\n",
       "    'gr': 'ANUM=(дат,мн|твор,ед,муж|твор,ед,сред)'},\n",
       "   {'lex': 'третье',\n",
       "    'wt': 0.005203241379,\n",
       "    'gr': 'S,сред,неод=(дат,мн|твор,ед)'},\n",
       "   {'lex': 'третья', 'wt': 0.0003570851927, 'gr': 'S,жен,неод=дат,мн'}],\n",
       "  'text': 'третьим'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'открытый', 'wt': 0.959315763, 'gr': 'A=твор,мн,полн'},\n",
       "   {'lex': 'открывать',\n",
       "    'wt': 0.04068423698,\n",
       "    'gr': 'V=прош,твор,мн,прич,полн,сов,страд'}],\n",
       "  'text': 'открытыми'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'белый', 'wt': 0.9932845421, 'gr': 'A=твор,мн,полн'},\n",
       "   {'lex': 'белый', 'wt': 0.004325486119, 'gr': 'S,фам,муж,од=твор,мн'},\n",
       "   {'lex': 'белые', 'wt': 0.001358058754, 'gr': 'S,мн,неод=твор'},\n",
       "   {'lex': 'белые', 'wt': 0.001031912979, 'gr': 'S,мн,од=твор'},\n",
       "   {'lex': 'белая', 'wt': 0, 'gr': 'S,фам,жен,од=твор,мн'}],\n",
       "  'text': 'белыми'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'карлик', 'wt': 1, 'gr': 'S,муж,од=твор,мн'}],\n",
       "  'text': 'карликами'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'становиться',\n",
       "    'wt': 0.9821285244,\n",
       "    'gr': 'V,нп=прош,мн,изъяв,сов'},\n",
       "   {'lex': 'сталь',\n",
       "    'wt': 0.01787147557,\n",
       "    'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}],\n",
       "  'text': 'стали'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'сириус',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,гео,муж,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'Сириус'},\n",
       " {'text': ' '},\n",
       " {'analysis': [], 'text': 'B'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='},\n",
       "   {'lex': 'и', 'wt': 1.020511514e-05, 'gr': 'INTJ='},\n",
       "   {'lex': 'и',\n",
       "    'wt': 6.379604644e-06,\n",
       "    'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'},\n",
       "   {'lex': 'и', 'wt': 6.37957056e-06, 'gr': 'PART='}],\n",
       "  'text': 'и'}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analized_text[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
